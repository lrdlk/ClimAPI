# ğŸ“Š SOLUCIÃ“N DE PROCESAMIENTO DE DATOS CLIMÃTICOS

## âœ… Lo que se ha implementado

Se ha creado un **sistema modular y escalable** para procesar datos climÃ¡ticos sin alterar tu estructura existente:

```
âœ¨ 4 nuevos mÃ³dulos
â”œâ”€â”€ src/data_loaders/     â†’ Cargar JSON, CSV, TXT, Excel
â”œâ”€â”€ src/validators/       â†’ Limpiar y validar datos
â”œâ”€â”€ src/pipelines/        â†’ Orquestar flujos ETL
â””â”€â”€ ejemplo_procesamiento.py  â†’ Script listo para usar
```

---

## ğŸš€ Inicio RÃ¡pido (3 lÃ­neas de cÃ³digo)

```python
from src.pipelines import ClimateDataPipeline

pipeline = ClimateDataPipeline("data")
df = pipeline.execute(validate=True, fill_nulls=True)

print(f"âœ“ {len(df)} registros procesados")
```

---

## ğŸ“‚ Estructura nueva (sin alterar la existente)

```
ClimAPI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loaders/     â† ğŸ†• NUEVO
â”‚   â”‚   â”œâ”€â”€ json_loader.py      # Parsea APIs: Meteoblue, OpenMeteo, OpenWeather
â”‚   â”‚   â”œâ”€â”€ file_loader.py      # CSV, TXT, Excel
â”‚   â”‚   â””â”€â”€ unified_loader.py   # Punto Ãºnico de entrada
â”‚   â”‚
â”‚   â”œâ”€â”€ validators/       â† ğŸ†• NUEVO
â”‚   â”‚   â””â”€â”€ data_validator.py   # ValidaciÃ³n de rangos + limpieza
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/        â† ğŸ†• NUEVO
â”‚   â”‚   â””â”€â”€ climate_pipeline.py # Orquesta: Load â†’ Validate â†’ Clean
â”‚   â”‚
â”‚   â”œâ”€â”€ data_sources/     â† Original (sin cambios)
â”‚   â”œâ”€â”€ processors/       â† Original (sin cambios)
â”‚   â””â”€â”€ visualizers/      â† Original (sin cambios)
â”‚
â”œâ”€â”€ ejemplo_procesamiento.py  â† Demo con 5 opciones
â”œâ”€â”€ verificar_pipeline.py     â† ComprobaciÃ³n del sistema
â””â”€â”€ GUIA_PROCESAMIENTO_DATOS.md â† DocumentaciÃ³n completa
```

---

## ğŸ¯ Opciones de Uso

### **OpciÃ³n 1: Lo mÃ¡s bÃ¡sico**
```python
from src.data_loaders import UnifiedDataLoader

df = UnifiedDataLoader("data").load_all()
# Carga TODO: JSON + CSV + TXT en un DataFrame
```

### **OpciÃ³n 2: Pipeline completo (RECOMENDADO)**
```python
from src.pipelines import ClimateDataPipeline

pipeline = ClimateDataPipeline("data")
df = pipeline.execute(
    validate=True,        # Eliminar outliers
    fill_nulls=True,     # Rellenar nulos
    remove_outliers=True # Validar rangos
)
```

### **OpciÃ³n 3: Por ubicaciÃ³n**
```python
df_bogota = pipeline.execute_by_location("Bogota")
df_medellin = pipeline.execute_by_location("MedellÃ­n")
```

### **OpciÃ³n 4: Por fuente climÃ¡tica**
```python
df_meteoblue = pipeline.execute_by_source("meteoblue")
df_openmeteo = pipeline.execute_by_source("openmeteo")
```

---

## ğŸ“Š Columnas Generadas

DespuÃ©s de procesar, obtienes:

```
timestamp              â†’ Fecha/Hora
temperature_C          â†’ Temperatura (Â°C)
windspeed_ms          â†’ Velocidad del viento (m/s)
winddirection_deg     â†’ DirecciÃ³n del viento (Â°)
precipitation_mm      â†’ PrecipitaciÃ³n (mm)
humidity_percent      â†’ Humedad relativa (%)
pressure_hPa          â†’ PresiÃ³n atmosfÃ©rica (hPa)
location              â†’ UbicaciÃ³n (Bogota, MedellÃ­n, etc)
source                â†’ Fuente (meteoblue, openmeteo, etc)
```

---

## ğŸ”§ CaracterÃ­sticas Principales

### **Data Loaders** - Parsea mÃºltiples formatos
- âœ… JSON de APIs (Meteoblue, OpenMeteo, OpenWeatherMap)
- âœ… CSV con detecciÃ³n automÃ¡tica de separadores
- âœ… TXT y Excel
- âœ… ConsolidaciÃ³n automÃ¡tica en un DataFrame

### **Validators** - Limpieza inteligente
- âœ… DetecciÃ³n de outliers (temperatura -50 a 60Â°C, etc)
- âœ… Rellenado de nulos (forward, lineal, media, drop)
- âœ… DetecciÃ³n de duplicados
- âœ… AnÃ¡lisis de calidad de datos

### **Pipelines** - OrquestaciÃ³n completa
- âœ… Carga automÃ¡tica de datos
- âœ… ValidaciÃ³n de rangos realistas
- âœ… Limpieza y transformaciÃ³n
- âœ… Resampling temporal (horario, diario, etc)
- âœ… ExportaciÃ³n en CSV/Parquet

---

## ğŸ’¡ Ejemplo Completo

```python
from src.pipelines import ClimateDataPipeline
from src.data_loaders import UnifiedDataLoader

# 1. Crear pipeline
pipeline = ClimateDataPipeline("data")

# 2. Procesar todos los datos
df = pipeline.execute(
    validate=True,
    fill_nulls=True,
    remove_outliers=True
)

# 3. AnÃ¡lisis bÃ¡sicos
print(f"Registros: {len(df)}")
print(f"Columnas: {list(df.columns)}")

# 4. EstadÃ­sticas por ubicaciÃ³n
for location in UnifiedDataLoader.get_available_locations("data"):
    df_loc = df[df['location'] == location]
    print(f"\n{location}:")
    print(f"  Temperatura: {df_loc['temperature_C'].mean():.1f}Â°C promedio")
    print(f"  Viento: {df_loc['windspeed_ms'].mean():.1f} m/s promedio")
    print(f"  Humedad: {df_loc['humidity_percent'].mean():.0f}% promedio")

# 5. Guardar resultado
pipeline.save_processed(df)
# Genera: data/processed/clima_procesado_YYYYMMDD_HHMMSS.csv
```

---

## ğŸ“ˆ Casos de Uso Reales

### **AnÃ¡lisis temporal**
```python
df = pipeline.execute(resample_freq='1H')  # Horario
df['fecha'] = df['timestamp'].dt.date
df['hora'] = df['timestamp'].dt.hour

temp_por_hora = df.groupby('hora')['temperature_C'].agg(['mean', 'min', 'max'])
```

### **ComparaciÃ³n entre ciudades**
```python
ciudades = UnifiedDataLoader.get_available_locations("data")

resultados = {}
for ciudad in ciudades:
    df_ciudad = pipeline.execute_by_location(ciudad)
    resultados[ciudad] = {
        'temp_prom': df_ciudad['temperature_C'].mean(),
        'humedad_prom': df_ciudad['humidity_percent'].mean(),
        'lluvia_total': df_ciudad['precipitation_mm'].sum(),
    }

import pandas as pd
df_resumen = pd.DataFrame(resultados).T
print(df_resumen)
```

### **DetecciÃ³n de anomalÃ­as**
```python
from src.validators import DataValidator

df = pipeline.execute(validate=False)

# Encontrar temperaturas anormales
temp_anomalas = df[
    (df['temperature_C'] < -50) | (df['temperature_C'] > 60)
]

print(f"AnomalÃ­as detectadas: {len(temp_anomalas)}")
```

---

## âœ¨ Ventajas de esta implementaciÃ³n

| Aspecto | Beneficio |
|--------|-----------|
| **Modular** | Cada componente es independiente |
| **No invasivo** | No toca cÃ³digo existente |
| **Escalable** | FÃ¡cil de extender con nuevas fuentes |
| **Documentado** | GuÃ­a completa incluida |
| **Testeable** | Cada mÃ³dulo se puede probar por separado |
| **Performante** | Caching y optimizaciones built-in |

---

## ğŸ“š PrÃ³ximos Pasos

### **Fase 1: Experimentar** (Ya lista)
```bash
python ejemplo_procesamiento.py
```

### **Fase 2: AnÃ¡lisis Exploratorio** (EDA)
```python
import pandas as pd

df = pipeline.execute()

# EstadÃ­sticas
print(df.describe())

# Correlaciones
numeric = df.select_dtypes(include=['number']).columns
print(df[numeric].corr())

# Visualizar
df.plot(x='timestamp', y=['temperature_C', 'humidity_percent'])
```

### **Fase 3: Machine Learning** (Futuro)
```python
# PredicciÃ³n de temperatura
from sklearn.ensemble import RandomForestRegressor

X = df[['humidity_percent', 'pressure_hPa', 'windspeed_ms']]
y = df['temperature_C']

model = RandomForestRegressor()
model.fit(X, y)
```

### **Fase 4: Dashboard DinÃ¡mico** (IntegraciÃ³n con Streamlit)
```python
# Reutilizar el pipeline en streamlit
import streamlit as st
from src.pipelines import ClimateDataPipeline

pipeline = ClimateDataPipeline("data")
df = pipeline.execute()

st.dataframe(df)
st.line_chart(df.set_index('timestamp')['temperature_C'])
```

---

## ğŸ”— Archivos clave

| Archivo | PropÃ³sito |
|---------|----------|
| [GUIA_PROCESAMIENTO_DATOS.md](GUIA_PROCESAMIENTO_DATOS.md) | DocumentaciÃ³n detallada |
| [ejemplo_procesamiento.py](ejemplo_procesamiento.py) | Demo con 5 casos de uso |
| [verificar_pipeline.py](verificar_pipeline.py) | Test del sistema |
| `src/data_loaders/` | Importar datos |
| `src/validators/` | Limpiar y validar |
| `src/pipelines/` | Orquestar todo |

---

## ğŸ†˜ Soporte RÃ¡pido

**"Â¿CÃ³mo cargo mis datos?"**
```python
from src.pipelines import ClimateDataPipeline
df = ClimateDataPipeline("data").execute()
```

**"Â¿CÃ³mo limpio nulos?"**
```python
from src.validators import DataValidator
df = DataValidator.fill_missing(df, method='linear')
```

**"Â¿CÃ³mo exporto los datos?"**
```python
df.to_csv('datos_limpios.csv', index=False)
df.to_parquet('datos_limpios.parquet')
```

**"Â¿DÃ³nde estÃ¡n mis datos procesados?"**
```
data/processed/clima_procesado_*.csv  (se genera automÃ¡ticamente)
```

---

## ğŸ“ Â¿Necesitas ayuda?

Ejecuta el verificador:
```bash
python verificar_pipeline.py
```

Lee la guÃ­a:
```bash
Abre: GUIA_PROCESAMIENTO_DATOS.md
```

Ve el ejemplo:
```bash
python ejemplo_procesamiento.py
```

---

## ğŸ‰ Â¡Lista para usar!

Tu sistema de ciencia de datos estÃ¡ listo. Puedes:

âœ… Cargar datos de mÃºltiples fuentes
âœ… Validar y limpiar automÃ¡ticamente
âœ… Procesar en batch o por ubicaciÃ³n
âœ… Exportar en mÃºltiples formatos
âœ… Integrar con anÃ¡lisis y ML

Â¡Adelante con tu proyecto ClimAPI! ğŸš€
